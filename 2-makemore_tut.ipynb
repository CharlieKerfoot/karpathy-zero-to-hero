{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3132fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/names.txt', 'r') as f:\n",
    "    words = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89e9098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a1d8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c13093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5fc4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bca9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '.',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = ['.']\n",
    "chars += sorted(list(set(''.join(words))))\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b121691",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6375444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = N.float()\n",
    "P /= N.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e86a7e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kae.\n",
      "merahavah.\n",
      "kake.\n",
      "bra.\n",
      "lyesahaitliarer.\n",
      "ixieze.\n",
      "a.\n",
      "tan.\n",
      "br.\n",
      "julengnayn.\n",
      "con.\n",
      "c.\n",
      "phlare.\n",
      "lubrdiziylaylesa.\n",
      "an.\n",
      "za.\n",
      "a.\n",
      "mud.\n",
      "bh.\n",
      "hyleliusari.\n",
      "anaee.\n",
      "jahianielenaneder.\n",
      "kargeriaka.\n",
      "iyn.\n",
      "ma.\n",
      "cawbeyeriyaijarelanolueaxa.\n",
      "h.\n",
      "ge.\n",
      "cannsayarofindedelly.\n",
      "jon.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(30):\n",
    "    ix = 0\n",
    "    out = []\n",
    "    while True:\n",
    "        ix = torch.multinomial(P[ix], 1, True).item()\n",
    "        out.append(itos[ix])\n",
    "        if (ix == 0):\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "32728c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13,  ..., 25, 26, 24]),\n",
       " tensor([ 5, 13, 13,  ..., 26, 24,  0]))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65df3eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e1709aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127985010>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27, 27), requires_grad=True)\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "455552d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0040, 0.0487, 0.0872, 0.2047, 0.0727, 0.0296, 0.0523, 0.0125, 0.0165,\n",
       "         0.0388, 0.0221, 0.0077, 0.0871, 0.0084, 0.0122, 0.0451, 0.0304, 0.0054,\n",
       "         0.0648, 0.0112, 0.0072, 0.0731, 0.0039, 0.0318, 0.0071, 0.0056, 0.0101],\n",
       "        [0.0236, 0.0219, 0.0024, 0.0317, 0.0061, 0.0440, 0.0437, 0.0659, 0.0084,\n",
       "         0.0089, 0.0061, 0.0203, 0.0068, 0.0351, 0.0152, 0.0061, 0.0267, 0.0173,\n",
       "         0.0956, 0.0354, 0.0121, 0.0316, 0.0371, 0.0234, 0.1822, 0.0378, 0.1546],\n",
       "        [0.0211, 0.0046, 0.0179, 0.0560, 0.0079, 0.0147, 0.0969, 0.0145, 0.0062,\n",
       "         0.0899, 0.0199, 0.0927, 0.0179, 0.0034, 0.0054, 0.0138, 0.0308, 0.0337,\n",
       "         0.0450, 0.0898, 0.0212, 0.0439, 0.0162, 0.0515, 0.0698, 0.0153, 0.1000],\n",
       "        [0.0211, 0.0046, 0.0179, 0.0560, 0.0079, 0.0147, 0.0969, 0.0145, 0.0062,\n",
       "         0.0899, 0.0199, 0.0927, 0.0179, 0.0034, 0.0054, 0.0138, 0.0308, 0.0337,\n",
       "         0.0450, 0.0898, 0.0212, 0.0439, 0.0162, 0.0515, 0.0698, 0.0153, 0.1000],\n",
       "        [0.0028, 0.0032, 0.0054, 0.4168, 0.0046, 0.0076, 0.0183, 0.0015, 0.0949,\n",
       "         0.0033, 0.0092, 0.0065, 0.0127, 0.0060, 0.0531, 0.0150, 0.0017, 0.1420,\n",
       "         0.0101, 0.0090, 0.0036, 0.0041, 0.0061, 0.0039, 0.1103, 0.0265, 0.0216]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True) #These two lines are the softmax\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a29b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram: .e\n",
      "Probs: tensor([0.0040, 0.0487, 0.0872, 0.2047, 0.0727, 0.0296, 0.0523, 0.0125, 0.0165,\n",
      "        0.0388, 0.0221, 0.0077, 0.0871, 0.0084, 0.0122, 0.0451, 0.0304, 0.0054,\n",
      "        0.0648, 0.0112, 0.0072, 0.0731, 0.0039, 0.0318, 0.0071, 0.0056, 0.0101])\n",
      "Label: 0.029570626094937325\n",
      "Log Likelihood: -3.5209736824035645\n",
      "Negative Log Likelihood: 3.5209736824035645\n",
      "----------------\n",
      "Bigram: em\n",
      "Probs: tensor([0.0236, 0.0219, 0.0024, 0.0317, 0.0061, 0.0440, 0.0437, 0.0659, 0.0084,\n",
      "        0.0089, 0.0061, 0.0203, 0.0068, 0.0351, 0.0152, 0.0061, 0.0267, 0.0173,\n",
      "        0.0956, 0.0354, 0.0121, 0.0316, 0.0371, 0.0234, 0.1822, 0.0378, 0.1546])\n",
      "Label: 0.03510763496160507\n",
      "Log Likelihood: -3.349336624145508\n",
      "Negative Log Likelihood: 3.349336624145508\n",
      "----------------\n",
      "Bigram: mm\n",
      "Probs: tensor([0.0211, 0.0046, 0.0179, 0.0560, 0.0079, 0.0147, 0.0969, 0.0145, 0.0062,\n",
      "        0.0899, 0.0199, 0.0927, 0.0179, 0.0034, 0.0054, 0.0138, 0.0308, 0.0337,\n",
      "        0.0450, 0.0898, 0.0212, 0.0439, 0.0162, 0.0515, 0.0698, 0.0153, 0.1000])\n",
      "Label: 0.003409249009564519\n",
      "Log Likelihood: -5.681263446807861\n",
      "Negative Log Likelihood: 5.681263446807861\n",
      "----------------\n",
      "Bigram: ma\n",
      "Probs: tensor([0.0211, 0.0046, 0.0179, 0.0560, 0.0079, 0.0147, 0.0969, 0.0145, 0.0062,\n",
      "        0.0899, 0.0199, 0.0927, 0.0179, 0.0034, 0.0054, 0.0138, 0.0308, 0.0337,\n",
      "        0.0450, 0.0898, 0.0212, 0.0439, 0.0162, 0.0515, 0.0698, 0.0153, 0.1000])\n",
      "Label: 0.004578295163810253\n",
      "Log Likelihood: -5.386428356170654\n",
      "Negative Log Likelihood: 5.386428356170654\n",
      "----------------\n",
      "Bigram: a.\n",
      "Probs: tensor([0.0028, 0.0032, 0.0054, 0.4168, 0.0046, 0.0076, 0.0183, 0.0015, 0.0949,\n",
      "        0.0033, 0.0092, 0.0065, 0.0127, 0.0060, 0.0531, 0.0150, 0.0017, 0.1420,\n",
      "        0.0101, 0.0090, 0.0036, 0.0041, 0.0061, 0.0039, 0.1103, 0.0265, 0.0216])\n",
      "Label: 0.002752905013039708\n",
      "Log Likelihood: -5.895098686218262\n",
      "Negative Log Likelihood: 5.895098686218262\n",
      "----------------\n",
      "Avg NLL: 4.76662015914917\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "    print(f\"Bigram: {itos[x]}{itos[y]}\")\n",
    "    print(f\"Probs: {probs[i]}\")\n",
    "    p = probs[i, y]\n",
    "    print(f\"Label: {p.item()}\")\n",
    "    print(f\"Log Likelihood: {torch.log(p).item()}\")\n",
    "    nlls[i] = -torch.log(p).item()\n",
    "    print(f\"Negative Log Likelihood: {nlls[i]}\")\n",
    "    print(\"----------------\")\n",
    "print(f\"Avg NLL: {nlls.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e456a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01b298e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0296),\n",
       " tensor(0.0351),\n",
       " tensor(0.0034),\n",
       " tensor(0.0046),\n",
       " tensor(0.0028))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0,5], probs[1,13], probs[2,13], probs[3,1], probs[4,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a050483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0296, 0.0351, 0.0034, 0.0046, 0.0028])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([probs[i, y] for i, y in enumerate(ys)])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6056c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0296, 0.0351, 0.0034, 0.0046, 0.0028])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(5), ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4188bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(W, xs, ys, lr, epoch):\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = torch.matmul(xenc, W)\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    labels = probs[torch.arange(len(ys)), ys]\n",
    "    loss = -labels.log().mean()\n",
    "\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    W.data -= lr * W.grad\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1} | Loss: {loss: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "26bc2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27, 27), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9d875954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss:  2.45779\n",
      "Epoch: 2 | Loss:  2.45772\n",
      "Epoch: 3 | Loss:  2.45777\n",
      "Epoch: 4 | Loss:  2.45770\n",
      "Epoch: 5 | Loss:  2.45775\n",
      "Epoch: 6 | Loss:  2.45767\n",
      "Epoch: 7 | Loss:  2.45773\n",
      "Epoch: 8 | Loss:  2.45765\n",
      "Epoch: 9 | Loss:  2.45770\n",
      "Epoch: 10 | Loss:  2.45763\n",
      "Epoch: 11 | Loss:  2.45768\n",
      "Epoch: 12 | Loss:  2.45761\n",
      "Epoch: 13 | Loss:  2.45766\n",
      "Epoch: 14 | Loss:  2.45759\n",
      "Epoch: 15 | Loss:  2.45764\n",
      "Epoch: 16 | Loss:  2.45757\n",
      "Epoch: 17 | Loss:  2.45762\n",
      "Epoch: 18 | Loss:  2.45755\n",
      "Epoch: 19 | Loss:  2.45760\n",
      "Epoch: 20 | Loss:  2.45753\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "lr = 75\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  train_loop(W, xs, ys, lr, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6814b3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2622e-02, 6.6671e+00, 1.9741e+00, 2.3309e+00, 2.5547e+00, 2.3143e+00,\n",
       "         6.2998e-01, 1.0110e+00, 1.3209e+00, 8.9306e-01, 3.6614e+00, 4.4793e+00,\n",
       "         2.3762e+00, 3.8368e+00, 1.7322e+00, 5.9521e-01, 7.7815e-01, 1.3857e-01,\n",
       "         2.4775e+00, 3.1065e+00, 1.9771e+00, 1.1739e-01, 5.6799e-01, 4.6367e-01,\n",
       "         2.0209e-01, 8.0839e-01, 1.4041e+00],\n",
       "        [8.5393e+00, 8.7130e-01, 8.4776e-01, 7.3636e-01, 1.6352e+00, 1.0848e+00,\n",
       "         2.0976e-01, 2.6301e-01, 3.6801e+00, 2.5951e+00, 2.7397e-01, 8.9013e-01,\n",
       "         3.9942e+00, 2.5698e+00, 9.4280e+00, 9.8639e-02, 1.2835e-01, 9.3965e-02,\n",
       "         5.1878e+00, 1.7549e+00, 1.0770e+00, 5.9678e-01, 1.3080e+00, 2.5205e-01,\n",
       "         2.8494e-01, 3.2302e+00, 6.8146e-01],\n",
       "        [6.8272e+00, 1.9693e+01, 2.0411e+00, 3.7171e-01, 3.7457e+00, 4.0432e+01,\n",
       "         2.3702e-01, 2.4333e-01, 2.2553e+00, 1.3233e+01, 2.4425e-01, 1.7405e-01,\n",
       "         6.1414e+00, 2.7301e-01, 4.2592e-01, 6.2660e+00, 2.2343e-01, 2.2036e-01,\n",
       "         5.2042e+01, 3.8361e-01, 1.6615e-01, 2.4687e+00, 2.9255e-01, 3.3341e-01,\n",
       "         2.5618e-01, 4.8915e+00, 3.2941e-01],\n",
       "        [3.3859e+00, 2.9466e+01, 1.6349e-01, 1.3692e+00, 1.9160e-01, 1.9882e+01,\n",
       "         1.9720e-01, 2.3016e-01, 2.3984e+01, 9.7144e+00, 2.1539e-01, 1.1349e+01,\n",
       "         4.0793e+00, 1.4575e-01, 1.8784e-01, 1.3673e+01, 2.0952e-01, 3.7390e-01,\n",
       "         2.6156e+00, 2.8259e-01, 1.1164e+00, 1.0425e+00, 1.8528e-01, 1.2838e-01,\n",
       "         1.4566e-01, 3.6408e+00, 2.4751e-01],\n",
       "        [1.2237e+01, 3.0963e+01, 1.5639e-01, 1.0807e-01, 3.5032e+00, 3.0487e+01,\n",
       "         1.0267e-01, 5.3902e-01, 2.7646e+00, 1.5997e+01, 2.7272e-01, 1.1029e-01,\n",
       "         1.3757e+00, 6.6555e-01, 6.9501e-01, 8.9537e+00, 1.2921e-01, 1.6426e-01,\n",
       "         1.0048e+01, 5.4355e-01, 1.1496e-01, 2.1443e+00, 3.9014e-01, 4.7984e-01,\n",
       "         1.5589e-01, 7.5021e+00, 1.6304e-01],\n",
       "        [1.6551e+01, 2.8211e+00, 5.0225e-01, 6.3525e-01, 1.5952e+00, 5.2811e+00,\n",
       "         3.4013e-01, 5.1888e-01, 6.3109e-01, 3.3987e+00, 2.2809e-01, 7.3915e-01,\n",
       "         1.3496e+01, 3.1951e+00, 1.1115e+01, 1.1173e+00, 3.4428e-01, 7.1289e-02,\n",
       "         8.1359e+00, 3.5774e+00, 2.4097e+00, 2.8610e-01, 1.9235e+00, 2.0742e-01,\n",
       "         5.4797e-01, 4.4459e+00, 7.5162e-01],\n",
       "        [8.1515e+00, 2.5738e+01, 4.3768e-01, 4.4001e-01, 3.6154e-01, 1.2844e+01,\n",
       "         4.1069e+00, 4.8955e-01, 4.7009e-01, 1.6858e+01, 5.1857e-01, 5.7958e-01,\n",
       "         1.7350e+00, 3.6601e-01, 5.8865e-01, 5.8684e+00, 2.2996e-01, 4.9107e-01,\n",
       "         1.1865e+01, 5.8474e-01, 1.6220e+00, 6.1672e-01, 4.4708e-01, 1.9954e-01,\n",
       "         3.8667e-01, 1.3451e+00, 5.0354e-01],\n",
       "        [4.4143e+00, 1.3721e+01, 3.0271e-01, 2.0968e-01, 6.1141e-01, 1.3888e+01,\n",
       "         2.2277e-01, 9.5137e-01, 1.4977e+01, 7.8547e+00, 2.7813e-01, 2.0677e-01,\n",
       "         1.1536e+00, 3.1065e-01, 9.8270e-01, 3.3610e+00, 2.5424e-01, 1.9793e-01,\n",
       "         8.3157e+00, 1.1176e+00, 1.1743e+00, 3.4439e+00, 1.9002e-01, 9.7251e-01,\n",
       "         1.7335e-01, 1.1739e+00, 2.4753e-01],\n",
       "        [5.3279e+01, 4.9626e+01, 2.2611e-01, 1.5730e-01, 4.7209e-01, 1.4873e+01,\n",
       "         1.4253e-01, 1.5282e-01, 1.4786e-01, 1.6091e+01, 2.2105e-01, 5.6268e-01,\n",
       "         4.0471e+00, 2.5395e+00, 3.0054e+00, 6.3061e+00, 1.2072e-01, 1.3820e-01,\n",
       "         4.4680e+00, 6.2708e-01, 1.5154e+00, 3.6261e+00, 7.7901e-01, 2.5739e-01,\n",
       "         1.3339e-01, 4.6673e+00, 3.9919e-01],\n",
       "        [6.2769e+00, 6.1660e+00, 2.7700e-01, 1.2833e+00, 1.1093e+00, 4.1685e+00,\n",
       "         2.5429e-01, 1.0790e+00, 2.3916e-01, 2.0636e-01, 1.9122e-01, 1.1219e+00,\n",
       "         3.3917e+00, 1.0765e+00, 5.3614e+00, 1.4826e+00, 1.3325e-01, 1.3084e-01,\n",
       "         2.1408e+00, 3.3186e+00, 1.3640e+00, 2.7448e-01, 6.7804e-01, 3.0328e-02,\n",
       "         2.2402e-01, 1.9643e+00, 6.9821e-01],\n",
       "        [4.4778e+00, 9.7641e+01, 3.3853e-01, 4.1632e-01, 3.5879e-01, 2.9037e+01,\n",
       "         2.6206e-01, 2.1305e-01, 2.7023e+00, 7.6985e+00, 2.7593e-01, 2.4428e-01,\n",
       "         5.2197e-01, 3.5489e-01, 2.1285e-01, 3.1628e+01, 2.6413e-01, 3.0791e-01,\n",
       "         5.6871e-01, 5.3274e-01, 2.1764e-01, 1.3224e+01, 2.3508e-01, 2.9298e-01,\n",
       "         2.2823e-01, 1.6258e-01, 1.6746e-01],\n",
       "        [1.2481e+01, 5.9899e+01, 2.2549e-01, 2.1361e-01, 2.0922e-01, 3.0922e+01,\n",
       "         2.0999e-01, 1.7641e-01, 1.0539e+01, 1.7542e+01, 1.7842e-01, 5.8422e-01,\n",
       "         4.7104e+00, 2.6463e-01, 7.4918e-01, 1.1822e+01, 1.8478e-01, 1.6453e-01,\n",
       "         3.6669e+00, 3.1784e+00, 5.2083e-01, 1.5935e+00, 2.2133e-01, 1.0446e+00,\n",
       "         1.5904e-01, 1.3035e+01, 1.9408e-01],\n",
       "        [1.9274e+01, 3.8489e+01, 7.4149e-01, 3.5790e-01, 2.0095e+00, 4.2863e+01,\n",
       "         3.1492e-01, 1.2779e-01, 2.6712e-01, 3.6390e+01, 1.3018e-01, 3.4346e-01,\n",
       "         1.9729e+01, 8.6024e-01, 2.2291e-01, 1.0143e+01, 2.3092e-01, 1.1021e-01,\n",
       "         2.4325e-01, 1.3622e+00, 1.1102e+00, 4.7411e+00, 1.0376e+00, 2.2673e-01,\n",
       "         9.2455e-02, 2.3296e+01, 1.7568e-01],\n",
       "        [1.0650e+01, 5.3644e+01, 2.2716e+00, 9.9359e-01, 4.2238e-01, 1.6911e+01,\n",
       "         1.3086e-01, 1.0040e-01, 1.0967e-01, 2.5991e+01, 1.5638e-01, 1.3280e-01,\n",
       "         1.7606e-01, 3.4345e+00, 3.6664e-01, 9.3236e+00, 7.2244e-01, 1.2116e-01,\n",
       "         1.9595e+00, 6.3956e-01, 8.5512e-02, 2.8325e+00, 1.1285e-01, 1.3963e-01,\n",
       "         1.2696e-01, 5.9027e+00, 2.2661e-01],\n",
       "        [5.9849e+01, 2.6340e+01, 9.3902e-02, 1.8760e+00, 6.2222e+00, 1.2019e+01,\n",
       "         1.1849e-01, 2.4072e+00, 2.2487e-01, 1.5259e+01, 3.7744e-01, 5.0147e-01,\n",
       "         1.7167e+00, 1.7198e-01, 1.6861e+01, 4.3812e+00, 8.3673e-02, 6.9123e-02,\n",
       "         3.7589e-01, 2.4515e+00, 3.9121e+00, 8.3941e-01, 4.7476e-01, 1.1365e-01,\n",
       "         8.6508e-02, 4.1068e+00, 1.2738e+00],\n",
       "        [5.0415e+00, 8.7679e-01, 8.2368e-01, 6.7024e-01, 1.1187e+00, 7.7648e-01,\n",
       "         2.0087e-01, 2.5774e-01, 1.0066e+00, 4.0456e-01, 1.0675e-01, 3.9853e-01,\n",
       "         3.6494e+00, 1.5375e+00, 1.4220e+01, 6.7615e-01, 5.5808e-01, 5.6226e-02,\n",
       "         6.2448e+00, 2.9710e+00, 6.9385e-01, 1.6201e+00, 1.0361e+00, 6.7024e-01,\n",
       "         2.6331e-01, 6.0531e-01, 3.1601e-01],\n",
       "        [2.5808e+00, 1.8835e+01, 3.1793e-01, 2.7805e-01, 4.6425e-01, 1.7735e+01,\n",
       "         4.3883e-01, 3.1496e-01, 1.8377e+01, 5.2249e+00, 4.7318e-01, 4.1239e-01,\n",
       "         1.1417e+00, 3.0915e-01, 4.2075e-01, 5.0278e+00, 3.0499e+00, 3.9154e-01,\n",
       "         1.3520e+01, 9.9119e-01, 1.0586e+00, 5.3257e-01, 2.4477e-01, 3.2163e-01,\n",
       "         4.3457e-01, 5.2221e-01, 4.9774e-01],\n",
       "        [2.7683e+00, 2.0780e+00, 6.4557e-01, 1.8741e-01, 4.7355e-01, 3.9056e-01,\n",
       "         1.1321e+00, 9.3279e-01, 1.5726e-01, 6.5595e-01, 1.1205e+00, 8.2114e-01,\n",
       "         9.5002e-01, 8.7918e-02, 7.0727e-01, 4.3984e-01, 9.2409e-01, 1.1695e+00,\n",
       "         1.1144e-01, 1.0513e+00, 8.8040e-01, 5.9893e+01, 1.1567e-01, 8.6367e-01,\n",
       "         5.3680e-01, 3.7845e-01, 2.5117e-01],\n",
       "        [1.1446e+01, 1.9588e+01, 3.3502e-01, 8.1731e-01, 1.5498e+00, 1.4108e+01,\n",
       "         1.0705e-01, 6.2550e-01, 1.0005e+00, 2.5218e+01, 2.0896e-01, 7.4231e-01,\n",
       "         3.4295e+00, 1.3418e+00, 1.1587e+00, 7.2218e+00, 1.2764e-01, 1.3406e-01,\n",
       "         3.5293e+00, 1.5747e+00, 1.7245e+00, 2.0905e+00, 6.5848e-01, 1.8107e-01,\n",
       "         7.7062e-02, 6.4234e+00, 1.9592e-01],\n",
       "        [1.0966e+01, 1.1267e+01, 1.9194e-01, 5.4510e-01, 1.0389e-01, 8.2892e+00,\n",
       "         7.2512e-02, 6.9767e-02, 1.2056e+01, 6.4106e+00, 5.6372e-02, 7.5345e-01,\n",
       "         2.6062e+00, 8.2905e-01, 2.1004e-01, 4.9735e+00, 4.5963e-01, 6.0635e-02,\n",
       "         4.9784e-01, 4.3159e+00, 7.1715e+00, 1.7229e+00, 1.3727e-01, 2.0914e-01,\n",
       "         5.5278e-02, 2.0048e+00, 1.0270e-01],\n",
       "        [1.1062e+01, 2.3587e+01, 1.3275e-01, 3.2069e-01, 1.3718e-01, 1.6427e+01,\n",
       "         1.5548e-01, 1.4668e-01, 1.4838e+01, 1.2190e+01, 1.0348e-01, 5.4409e-02,\n",
       "         3.0231e+00, 1.7587e-01, 4.5836e-01, 1.5299e+01, 1.3128e-01, 1.3743e-01,\n",
       "         8.0457e+00, 6.9629e-01, 8.5523e+00, 1.7270e+00, 2.8598e-01, 2.5660e-01,\n",
       "         1.4546e-01, 7.7924e+00, 2.3533e+00],\n",
       "        [2.2308e+00, 2.3465e+00, 1.4782e+00, 1.4782e+00, 1.9559e+00, 2.4333e+00,\n",
       "         2.8300e-01, 6.6803e-01, 8.2576e-01, 1.7388e+00, 2.3063e-01, 1.3332e+00,\n",
       "         4.3422e+00, 2.2163e+00, 3.9662e+00, 1.8311e-01, 2.4075e-01, 1.6913e-01,\n",
       "         5.9760e+00, 6.8435e+00, 1.1737e+00, 1.3279e-01, 5.2419e-01, 1.2318e+00,\n",
       "         4.7876e-01, 2.0946e-01, 6.3402e-01],\n",
       "        [1.3186e+01, 1.0141e+02, 7.1177e-01, 2.3658e-01, 5.7211e-01, 8.9643e+01,\n",
       "         5.3656e-01, 1.7171e-01, 2.8886e-01, 1.4420e+02, 6.0299e-01, 2.7260e-01,\n",
       "         1.6992e+00, 4.4813e-01, 7.6567e-01, 2.3598e+01, 6.9333e-01, 3.9653e-01,\n",
       "         6.6416e+00, 4.6916e-01, 5.8443e-01, 1.1084e+00, 7.9796e-01, 5.8183e-01,\n",
       "         5.4992e-01, 1.8489e+01, 5.5022e-01],\n",
       "        [4.4266e+00, 2.5883e+01, 1.8184e-01, 5.1929e-01, 7.3920e-01, 1.3651e+01,\n",
       "         3.0562e-01, 5.2909e-01, 1.7611e+00, 1.3558e+01, 1.8533e-01, 6.1669e-01,\n",
       "         5.2575e-01, 6.5175e-01, 5.0990e+00, 2.9869e+00, 4.8708e-01, 3.7700e-01,\n",
       "         1.6009e+00, 1.4498e+00, 8.4691e-01, 2.0510e+00, 3.7371e-01, 4.7173e-01,\n",
       "         5.2696e-01, 6.5070e+00, 3.6236e-01],\n",
       "        [1.6219e+01, 1.0075e+01, 5.7083e-01, 6.2428e-01, 2.6470e-01, 3.3824e+00,\n",
       "         8.6438e-01, 1.5415e-01, 5.1568e-02, 9.9749e+00, 1.7835e-01, 6.9388e-01,\n",
       "         3.5948e+00, 5.4119e-01, 6.2190e-01, 3.7729e+00, 2.3161e-01, 4.9324e-01,\n",
       "         6.7743e-01, 2.6805e+00, 6.6872e+00, 3.3510e-01, 9.5334e-02, 4.8951e-01,\n",
       "         2.8487e+00, 2.7176e+00, 1.2764e+00],\n",
       "        [1.6103e+01, 1.7195e+01, 2.1814e-01, 9.1781e-01, 2.1784e+00, 2.4112e+00,\n",
       "         1.0864e-01, 2.3944e-01, 1.7408e-01, 1.5362e+00, 1.8810e-01, 6.8453e-01,\n",
       "         8.8559e+00, 1.1829e+00, 1.4650e+01, 2.1704e+00, 1.2860e-01, 8.7290e-02,\n",
       "         2.3309e+00, 3.2138e+00, 8.2940e-01, 1.1267e+00, 8.4548e-01, 7.1607e-02,\n",
       "         2.2163e-01, 1.6899e-01, 6.2007e-01],\n",
       "        [1.0668e+01, 5.8260e+01, 4.1118e-01, 4.4742e-01, 4.4231e-01, 2.5154e+01,\n",
       "         1.6607e-01, 4.2144e-01, 2.6608e+00, 2.4542e+01, 3.5104e-01, 1.7104e-01,\n",
       "         8.1478e+00, 2.1214e+00, 4.4044e-01, 7.2612e+00, 1.7813e-01, 2.5130e-01,\n",
       "         1.9015e+00, 4.6742e-01, 4.5939e-01, 4.7242e+00, 1.6943e-01, 2.8989e-01,\n",
       "         3.6428e-01, 9.7829e+00, 2.7417e+00]], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a01d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     xenc \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mone_hot(torch\u001b[38;5;241m.\u001b[39mtensor([ix]), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      8\u001b[0m     logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(xenc, W)\n\u001b[1;32m      9\u001b[0m     counts \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mexp()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = torch.matmul(xenc, W)\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "        ix = torch.multinomial(probs, 1, True).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(\"\".join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
