{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d256c4b-7bbd-4934-8a6f-00e56e8d0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f37e735",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f90ba2d-1cb1-40f8-81a4-8b4cb9fa7c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c820ab-09ca-486d-b617-05616d5271e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['.'] + sorted(list(set(\"\".join(words))))\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fe9cc45-3faf-44ac-a36d-c3975fceb554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "block_size = 3\n",
    "\n",
    "random.shuffle(words)\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        X.append(context)\n",
    "        Y.append(stoi[ch])\n",
    "        context = context[1:] + [stoi[ch]]\n",
    "\n",
    "X, Y = torch.tensor(X), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17c7051a-fe51-4fae-94c1-9618b52370ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(.8 * len(X))\n",
    "val_split = int(.9 * len(X))\n",
    "\n",
    "xtr = X[:train_split]\n",
    "ytr = Y[:train_split]\n",
    "xval = X[train_split:val_split]\n",
    "yval = Y[train_split:val_split]\n",
    "xtest = X[val_split:]\n",
    "ytest = Y[val_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "e6ad06e0-ba37-4a54-a02e-1a5d70150b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 10\n",
    "layer_size = 400\n",
    "vocab_size = 27\n",
    "\n",
    "C = torch.randn((vocab_size, n_dim))\n",
    "w1 = torch.randn((n_dim * block_size, layer_size)) * (5/3)/((n_dim*block_size)**0.5)\n",
    "# b1 = torch.randn((layer_size)) * 0.01\n",
    "w2 = torch.randn((layer_size, vocab_size)) * 0.01\n",
    "b2 = torch.randn((vocab_size)) * 0\n",
    "\n",
    "bngain = torch.ones((1, layer_size))\n",
    "bnbias = torch.zeros((1, layer_size))\n",
    "\n",
    "bnmean_running = torch.zeros(1, layer_size)\n",
    "bnstd_running = torch.zeros(1, layer_size)\n",
    "\n",
    "parameters = [C, w1, w2, b2, bngain, bnbias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "93775856-a9ed-49e6-b197-c758b2c83f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "2d50e7d4-0149-4481-b337-d7dc1ea9ca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss:  2.0563\n",
      "Epoch: 1000 | Loss:  1.9024\n",
      "Epoch: 2000 | Loss:  1.8996\n",
      "Epoch: 3000 | Loss:  2.0817\n",
      "Epoch: 4000 | Loss:  1.8727\n",
      "Epoch: 5000 | Loss:  2.0839\n",
      "Epoch: 6000 | Loss:  1.8789\n",
      "Epoch: 7000 | Loss:  1.7424\n",
      "Epoch: 8000 | Loss:  2.0306\n",
      "Epoch: 9000 | Loss:  2.0354\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10000\n",
    "lr = 0.1\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    ix = torch.randint(0, xtr.shape[0], (batch_size,))\n",
    "    \n",
    "    x_enc = C[xtr[ix]]\n",
    "    hpreact = torch.matmul(x_enc.view(-1, n_dim * block_size), w1)\n",
    "    bmeani = hpreact.mean(0, keepdim=True)\n",
    "    bstdi = hpreact.std(0, keepdim=True)\n",
    "    hpreact = bngain * ((hpreact - bnmeani)/bnstdi) + bnbias\n",
    "\n",
    "    bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
    "    bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
    "    \n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = torch.matmul(h, w2) + b2\n",
    "    loss = F.cross_entropy(logits, ytr[ix])\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    if (i % (num_epochs/10) == 0):\n",
    "        print(f\"Epoch: {i} | Loss: {loss: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "d5ea6950-2aa5-4b1a-9539-ff59a732da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_enc = C[xtr]\n",
    "    hpreact = torch.matmul(x_enc.view(-1, n_dim * block_size), w1) + b1\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnstd = hpreact.std(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "73f6d25b-559f-48aa-8994-590960a158bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.0548861026763916\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_enc = C[xtr]\n",
    "    hpreact = torch.matmul(x_enc.view(-1, n_dim * block_size), w1) + b1\n",
    "    hpreact = bngain * ((hpreact - bnmean_running)/bnstd_running) + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = torch.matmul(h, w2) + b2\n",
    "    loss = F.cross_entropy(logits, ytr)\n",
    "    print(f\"train loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "3d73006a-6710-47c9-afab-737d4ec31ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 2.0843234062194824\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_enc = C[xval]\n",
    "    hpreact = torch.matmul(x_enc.view(-1, n_dim * block_size), w1) + b1\n",
    "    hpreact = bngain * ((hpreact - bnmean_running)/bnstd_running) + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = torch.matmul(h, w2) + b2\n",
    "    loss = F.cross_entropy(logits, yval)\n",
    "    print(f\"val loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "30df8f6b-0cb5-4f0c-8e9a-64efaccf9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, in_features, out_features, Bias=True):\n",
    "        self.w = torch.randn((in_features, out_features)) / in_features**.5\n",
    "        self.b = torch.randn(out_features) if Bias else None\n",
    "\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        out = torch.matmul(x, self.w)\n",
    "        out += self.b if self.b != None else 0\n",
    "        return out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.w] + ([] if self.b == None else [self.b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "f2a2861d-afce-403e-873a-e27fa6840dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1D():\n",
    "    def __init__(self, dim, eps=1e-05, momentum=0.1,):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        self.gain = torch.ones(dim)\n",
    "        self.bias = torch.zeros(dim)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        if self.training:\n",
    "            xmean = x.mean(0, keepdim=True)\n",
    "            xvar = x.var(0, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        out = self.gain * xhat + self.bias\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1-self.momentum)*self.running_mean + self.momentum*xmean\n",
    "                self.running_var = (1-self.momentum)*self.running_var + self.momentum*xvar\n",
    "        return out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gain, self.bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "2e968478-1a97-4059-869e-6ef4509b1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "c64caf0d-5fb2-47be-ba53-7ff0a3c9aaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132497\n"
     ]
    }
   ],
   "source": [
    "layer_size = 200\n",
    "\n",
    "C = torch.randn(vocab_size, n_dim)\n",
    "layers = [\n",
    "    Linear(n_dim*block_size, layer_size), Tanh(),\n",
    "    Linear(layer_size, layer_size), Tanh(),\n",
    "    Linear(layer_size, layer_size), Tanh(),\n",
    "    Linear(layer_size, layer_size), Tanh(),\n",
    "    Linear(layer_size, vocab_size)\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].w *= 0.1\n",
    "    for l in layers[:-1]:\n",
    "        if isinstance(l, Linear):\n",
    "            l.w *= 5/3\n",
    "\n",
    "parameters = [C] + [p for l in layers for p in l.parameters()]\n",
    "print(sum(p.nelement() for p in parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "513571a8-5b19-4d69-8258-7f532b94a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "3b4cae15-d43d-4719-834f-3dbf82bdccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss:  2.0393\n",
      "Epoch: 10000 | Loss:  1.8025\n",
      "Epoch: 20000 | Loss:  1.7611\n",
      "Epoch: 30000 | Loss:  1.7831\n",
      "Epoch: 40000 | Loss:  1.7340\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50000\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    ix = torch.randint(0, xtr.shape[0], (batch_size,))\n",
    "\n",
    "    x = C[xtr[ix]].view(-1, n_dim*block_size)\n",
    "    for l in layers:\n",
    "        x = l(x)\n",
    "    loss = F.cross_entropy(x, ytr[ix])\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Epoch: {i} | Loss: {loss: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "d6fffe18-866c-4f60-9655-28b0af0025dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9248042106628418\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = C[xtr].view(-1, n_dim*block_size)\n",
    "    for l in layers:\n",
    "        x = l(x)\n",
    "    loss = F.cross_entropy(x, ytr)\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "f5537884-bf08-4af1-a24c-20776dcc5620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.064256429672241\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = C[xval].view(-1, n_dim*block_size)\n",
    "    for l in layers:\n",
    "        x = l(x)\n",
    "    loss = F.cross_entropy(x, yval)\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "13f5dded-1e31-4d0a-be53-b36059974092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133324\n"
     ]
    }
   ],
   "source": [
    "C = torch.randn(vocab_size, n_dim)\n",
    "layers = [\n",
    "    Linear(n_dim*block_size, layer_size, Bias=False), BatchNorm1D(layer_size), Tanh(),\n",
    "    Linear(layer_size, layer_size, Bias=False), BatchNorm1D(layer_size), Tanh(),\n",
    "    Linear(layer_size, layer_size, Bias=False), BatchNorm1D(layer_size), Tanh(),\n",
    "    Linear(layer_size, layer_size, Bias=False), BatchNorm1D(layer_size), Tanh(),\n",
    "    Linear(layer_size, vocab_size, Bias=False), BatchNorm1D(vocab_size)\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].gain *= 0.1\n",
    "    for l in layers[:-1]:\n",
    "        if isinstance(l, Linear):\n",
    "            l.w *= 5/3\n",
    "\n",
    "parameters = [C] + [p for l in layers for p in l.parameters()]\n",
    "print(sum(p.nelement() for p in parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "f1f519b7-5576-4159-bcf3-afbf4b03a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "bf2553f7-d8d5-4443-a1ef-5a9903f29f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss:  2.1070\n",
      "Epoch: 10000 | Loss:  2.1247\n",
      "Epoch: 20000 | Loss:  1.6084\n",
      "Epoch: 30000 | Loss:  1.7507\n",
      "Epoch: 40000 | Loss:  1.6699\n",
      "Epoch: 50000 | Loss:  1.8256\n",
      "Epoch: 60000 | Loss:  1.8996\n",
      "Epoch: 70000 | Loss:  1.6073\n",
      "Epoch: 80000 | Loss:  2.3179\n",
      "Epoch: 90000 | Loss:  2.0406\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100000\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "\n",
    "for l in layers:\n",
    "    if (isinstance(l, BatchNorm1D)): l.training = True\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    ix = torch.randint(0, xtr.shape[0], (batch_size,))\n",
    "\n",
    "    x = C[xtr[ix]].view(-1, n_dim*block_size)\n",
    "    for l in layers:\n",
    "        x = l(x)\n",
    "    loss = F.cross_entropy(x, ytr[ix])\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Epoch: {i} | Loss: {loss: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "b4e3add3-73d9-4609-bf14-4a26fce1bec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9417372941970825\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = C[xtr].view(-1, n_dim*block_size)\n",
    "    for l in layers:\n",
    "        if isinstance(l, BatchNorm1D): l.training = False\n",
    "        x = l(x)\n",
    "    loss = F.cross_entropy(x, ytr)\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "9cc90064-0198-413a-b268-7bb65618a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0569443702697754\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = C[xval].view(-1, n_dim*block_size)\n",
    "    for l in layers:\n",
    "        if isinstance(l, BatchNorm1D): l.training = False\n",
    "        x = l(x)\n",
    "    loss = F.cross_entropy(x, yval)\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86ea8a-ea5e-414e-b06e-aedb3fed52ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
