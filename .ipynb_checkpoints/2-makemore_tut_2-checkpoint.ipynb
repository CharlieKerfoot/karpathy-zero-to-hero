{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f3b09e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('data/names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd2489f3-55ee-4f6a-9390-e64acc8bef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a157979d-cd19-48c3-b09e-82ec9035f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42f32428-5d18-4500-be84-7281136b7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = torch.zeros((27, 27), dtype=torch.int32)\n",
    "for word in words:\n",
    "    w = ['.'] + list(word) + ['.']\n",
    "    for ch1, ch2 in zip(w, w[1:]):\n",
    "        bigrams[stoi[ch1], stoi[ch2]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eca1918c-3477-4a82-9a03-710d0b2f91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = bigrams.float()\n",
    "P /= P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "474d6412-0db8-4b28-bfca-9fee35e78eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ttoli',\n",
       " 'jeme',\n",
       " 'olle',\n",
       " 'n',\n",
       " 'ise',\n",
       " 'mma',\n",
       " 'miy',\n",
       " 'ddamaivalbenaioupra',\n",
       " 'shll',\n",
       " 'grurmeraarandata']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 10\n",
    "samples = []\n",
    "\n",
    "for _ in range(n_samples):\n",
    "    sample = ''\n",
    "    ix = 0\n",
    "    while True:\n",
    "        ix = torch.multinomial(P[ix], 1).item()\n",
    "        if (ix == 0): break\n",
    "        sample += itos[ix]\n",
    "    samples.append(sample)\n",
    "    \n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0806c260-6a22-4e87-9b2d-b85b2db8566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for word in words:\n",
    "    w = ['.'] + list(word) + ['.']\n",
    "    for ch1, ch2 in zip(w, w[1:]):\n",
    "        xs.append(stoi[ch1])\n",
    "        ys.append(stoi[ch2])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "50bb72d1-b76b-460a-bcce-71b4ae011db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn((27, 27), dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f909549f-b120-4d82-a843-3db0f9db746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 1000/1000 [00:16<00:00, 62.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 1000\n",
    "lr = 50\n",
    "\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    # 1. Forward Pass\n",
    "    logits = w[xs]\n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    # 2. Calculate Loss\n",
    "    loss = (-probs[torch.arange(len(ys)), ys].log()).mean() # .001 * (w**2).mean() - regularization\n",
    "\n",
    "    # 3. Zero out gradients\n",
    "    w.grad = None\n",
    "\n",
    "    # 4. Backpropagate (Calculate gradients)\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step in negative gradient direction \n",
    "    w.data -= lr * w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a8f13afe-246f-4f2b-a981-0e1d5c5676f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trola\n",
      "jlmx\n",
      "olsebakieesmmtemrytrhamybmrlbenaldhpca\n",
      "srllkg\n",
      "krmmraalsniata\n",
      "ebu\n",
      "ba\n",
      "lkk\n",
      "olepadlkrtdrh\n",
      "obejbapsniakldhpbodnienypaoniyk\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "for _ in range(n_samples):\n",
    "    ix = 0\n",
    "    word = ''\n",
    "    while True:\n",
    "        logits = w[xs]\n",
    "        counts = torch.exp(logits)\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "        ix = torch.multinomial(probs[ix], 1).item()\n",
    "        if (ix == 0): break;\n",
    "        word += itos[ix]\n",
    "    print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
